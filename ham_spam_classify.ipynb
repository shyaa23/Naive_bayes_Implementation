{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Naive Bayes for Spam Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to classify the text into spam/ham using Naive Bayes algorithm. Naive Bayes is supervised learning algoirthm that uses probabilities to perform the classification. The following equation is used for classifying text messages:\n",
    "\n",
    "![image.png](https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f3637f468262bfbb4accb97da8110028_l3.svg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMSSpamCollection.txt',sep='\\t', header=None)\n",
    "data = data.rename(columns={0:'label',1:'text'})\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  text\n",
       "0   ham  4825\n",
       "1  spam   747"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check total number of ham and spam messages\n",
    "df_count = data.groupby(['label']).count().reset_index()\n",
    "df_count.plot(kind='bar',x='label',y='text')\n",
    "df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document consist of 4825 ham messages and 747 spam messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2. Data Pre-processing </h3>\n",
    "\n",
    "\n",
    "The following function \"clean_string\" was used to preprocess the text messages in the document. The entire document was converted into lower case, then the punctuations and stopwords were removed. Then, the text messages were tokenized and stemmed (Porter stemmer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>nah i think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                         clean_text\n",
       "0   ham  go jurong point crazi avail bugi n great world...\n",
       "1   ham                              ok lar joke wif u oni\n",
       "2  spam  free entri 2 wkli comp win fa cup final tkt 21...\n",
       "3   ham                u dun say earli hor u c alreadi say\n",
       "4   ham             nah i think goe usf live around though"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_string(df_raw):\n",
    "    stop = stopwords.words('english')\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    #stopwords removed and text converted to lower case\n",
    "    df_raw['text1'] = df_raw['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])).str.lower()\n",
    "\n",
    "    #remove punctuations\n",
    "    df_raw['no_punct'] = df_raw['text1'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "    \n",
    "    #porter stemmer\n",
    "    df_raw['tokenized_text']=df_raw['no_punct'].apply(lambda x : filter(None,x.split(\" \")))\n",
    "    df_raw['stemmed_text']=df_raw['tokenized_text'].apply(lambda x : [ps.stem(y) for y in x])\n",
    "    df_raw['clean_text']=df_raw['stemmed_text'].apply(lambda x : \" \".join(x))\n",
    "    df1 = df_raw[[\"label\", \"clean_text\"]]\n",
    "    return(df1)\n",
    "\n",
    "df = clean_string(df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3. Data Training </h3>\n",
    "\n",
    "<h4> STEPS </h4>\n",
    "\n",
    "1. Vocabulary: A dataframe of unique words from entire text message was created using \"get_vocab()\" function.\n",
    "\n",
    "2. The data was then split into train and test dataset. For each class (Ham/Spam) in the training set, following calculations were performed:\n",
    "\n",
    "    • spam_texts = training messages for which the classification is spam\n",
    "    • ham_texts = training messages for which the classification is ham\n",
    "\n",
    "    • total_prob_spam = Probability estimate of spam class\n",
    "    • total_prob_ham = Probability estimate of ham class\n",
    "\n",
    "    • words_spam = A single file for spam class (concatenated all spam Msgs)\n",
    "    • words_ham = A single file for ham class (concatenated all ham Msgs)\n",
    "\n",
    "    • ns = total number of word positions in words_spam (For spam)\n",
    "    • nh = total number of word positions in words_ham (For ham)\n",
    "\n",
    "    • spam_count = number of times each words occurs in words_spam\n",
    "    • ham_count = number of times each words occurs in words_ham\n",
    "\n",
    "    • spam_prob = Probability of kth word in vocabulary, given a message of type spam\n",
    "    • ham_prob = Probability of kth word in vocabulary, given a message of type ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(df): \n",
    "    #create list on unique words\n",
    "    main_series = df['clean_text'].str.split(' ',expand = True).stack().value_counts()\n",
    "    vocab_df1 = main_series.index.to_frame()\n",
    "    vocab_df = pd.DataFrame({'vocab':vocab_df1.index})\n",
    "    return(vocab_df)\n",
    "\n",
    "vocab_df = get_vocab(df)\n",
    "\n",
    "def for_each_class(vocab_df,train_df):\n",
    "    \n",
    "    vocabulary = len(vocab_df)\n",
    "    \n",
    "    #probability for two classes\n",
    "    spam_texts = train_df[train_df['label'] == 'spam']\n",
    "    ham_texts = train_df[train_df['label'] == 'ham']\n",
    "   \n",
    "    total_prob_spam = round((len(spam_texts)/len(train_df)), 2)\n",
    "    total_prob_ham = round((len(ham_texts)/len(train_df)), 2)\n",
    "    #return(total_prob_spam, total_prob_ham)\n",
    "    \n",
    "    #list of words in spam\n",
    "    #words in spam\n",
    "    words_spam = spam_texts['clean_text'].apply(lambda x: (x.split(\" \"))).sum(axis = 0)\n",
    "        \n",
    "    #total number of words in spam\n",
    "    ns = len(words_spam)\n",
    "    \n",
    "    #list of words in ham\n",
    "    words_ham = ham_texts['clean_text'].apply(lambda x: (x.split(\" \"))).sum(axis = 0)\n",
    "        \n",
    "    #total number of words in ham\n",
    "    nh = len(words_ham)\n",
    "       \n",
    "    spam_count = []\n",
    "    ham_count = []\n",
    "    ham_prob = []\n",
    "    spam_prob = []\n",
    "\n",
    "    for row in vocab_df['vocab']:\n",
    "        spam_count.append(words_spam.count(row))\n",
    "        ham_count.append(words_ham.count(row))\n",
    "    vocab_df['spam_count'] = spam_count   \n",
    "    vocab_df['ham_count'] = ham_count   \n",
    "\n",
    "    for row in vocab_df['spam_count']:\n",
    "        spam_prob.append(cal_probability(row,ns,vocabulary))\n",
    "\n",
    "    for row in vocab_df['ham_count']:\n",
    "        ham_prob.append(cal_probability(row,nh,vocabulary))\n",
    "\n",
    "    vocab_df['spam_prob'] = spam_prob   \n",
    "    vocab_df['ham_prob'] = ham_prob      \n",
    "    \n",
    "    return(vocab_df, total_prob_spam,total_prob_ham)\n",
    "       \n",
    "def cal_probability(nk,n,vocabs):\n",
    "    result = (nk+1)/(n+vocabs)\n",
    "    return result\n",
    "\n",
    "train_df = df.sample(frac=0.7,random_state=100)\n",
    "vocab_df, total_prob_spam,total_prob_ham= for_each_class(vocab_df,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>spam_count</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_prob</th>\n",
       "      <th>ham_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "      <td>28</td>\n",
       "      <td>1023</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>93</td>\n",
       "      <td>660</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.016271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>call</td>\n",
       "      <td>256</td>\n",
       "      <td>190</td>\n",
       "      <td>0.014327</td>\n",
       "      <td>0.004702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>you</td>\n",
       "      <td>91</td>\n",
       "      <td>276</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.006818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>214</td>\n",
       "      <td>0.006467</td>\n",
       "      <td>0.005292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>im</td>\n",
       "      <td>8</td>\n",
       "      <td>301</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.007434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>go</td>\n",
       "      <td>28</td>\n",
       "      <td>299</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.007385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>get</td>\n",
       "      <td>59</td>\n",
       "      <td>257</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.006351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>ur</td>\n",
       "      <td>102</td>\n",
       "      <td>162</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.004012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>it</td>\n",
       "      <td>7</td>\n",
       "      <td>225</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.005563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vocab  spam_count  ham_count  spam_prob  ham_prob\n",
       "0     i          28       1023   0.001617  0.025206\n",
       "1     u          93        660   0.005240  0.016271\n",
       "2  call         256        190   0.014327  0.004702\n",
       "3   you          91        276   0.005129  0.006818\n",
       "4     2         115        214   0.006467  0.005292\n",
       "5    im           8        301   0.000502  0.007434\n",
       "6    go          28        299   0.001617  0.007385\n",
       "7   get          59        257   0.003345  0.006351\n",
       "8    ur         102        162   0.005742  0.004012\n",
       "9    it           7        225   0.000446  0.005563"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4. Class Prediction </h3>\n",
    "\n",
    "Following functions were used to determine the class for each text messages in test dataset. \n",
    "\n",
    "For each row in the dataset, the text messages were split into word. For each words, the corresponding probability value were obtained from the trained dataset (vocab_df). The words not found in the vocabulary were ignored. After determining the probability of each word for every row, the product of probabilities of spam and ham for each sentence were calculated using log (log (a * b) = log(a) + log(b)) since the computation might result in arithmetic underflow.\n",
    "\n",
    "The class was then predicted as Ham if the probability values for ham class is higher than spam class and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(spam_val,ham_val):\n",
    "    if spam_val > ham_val:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'\n",
    "    \n",
    "def predict(test_df, vocab_df, total_prob_spam,total_prob_ham):   \n",
    "    test = test_df.reset_index()\n",
    "    test['spam_value']=\"\"\n",
    "    test['ham_value']=\"\"\n",
    "    test['Predicted_class']=\"\"\n",
    "\n",
    "    row_index = 0\n",
    "    for row in test['clean_text']:\n",
    "        p=row.split()\n",
    "        sum1,sum2, mainsum = 0,0,0\n",
    "        for i in p:\n",
    "            if i in vocab_df.vocab.values:\n",
    "                dfbb = int(vocab_df[vocab_df['vocab']==i].index[0]) #returns index number from vocab_df\n",
    "                #print(dfbb)\n",
    "                #print(i)\n",
    "                prob_val_spam = vocab_df['spam_prob'][dfbb]\n",
    "                sum1 = sum1 + math.log10(prob_val_spam)\n",
    "\n",
    "                prob_val_ham = vocab_df['ham_prob'][dfbb]\n",
    "                sum2 = sum2 + math.log10(prob_val_ham)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        mainsum1 = sum1+math.log10(total_prob_spam)\n",
    "        #print(mainsum1)\n",
    "        test['spam_value'][row_index] = mainsum1\n",
    "\n",
    "        mainsum2 = sum2+math.log10(total_prob_ham)\n",
    "        #print(mainsum2)\n",
    "        test['ham_value'][row_index] = mainsum2\n",
    "\n",
    "        test['Predicted_class'][row_index] = classify(mainsum1,mainsum2)\n",
    "\n",
    "        row_index+=1\n",
    "        \n",
    "    return(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "test_df = df.drop(train_df.index)\n",
    "vocab_df,total_prob_spam,total_prob_ham= for_each_class(vocab_df,train_df)\n",
    "test = predict(test_df, vocab_df, total_prob_spam,total_prob_ham) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>spam_value</th>\n",
       "      <th>ham_value</th>\n",
       "      <th>Predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "      <td>-74.8796</td>\n",
       "      <td>-93.0891</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "      <td>-33.1424</td>\n",
       "      <td>-25.6572</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>ham</td>\n",
       "      <td>even brother like speak me they treat like aid...</td>\n",
       "      <td>-38.4619</td>\n",
       "      <td>-32.6589</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>ham</td>\n",
       "      <td>as per request mell mell oru minnaminungint nu...</td>\n",
       "      <td>-67.9025</td>\n",
       "      <td>-63.7573</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>spam</td>\n",
       "      <td>six chanc win cash from 100 20000 pound txt cs...</td>\n",
       "      <td>-70.8023</td>\n",
       "      <td>-87.7866</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>ham</td>\n",
       "      <td>ive search right word thank breather i promis ...</td>\n",
       "      <td>-66.4925</td>\n",
       "      <td>-59.0313</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>ham</td>\n",
       "      <td>eh u rememb 2 spell name ye did he v naughti m...</td>\n",
       "      <td>-51.1316</td>\n",
       "      <td>-44.1937</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>ham</td>\n",
       "      <td>fine that way u feel that way gota b</td>\n",
       "      <td>-36.0186</td>\n",
       "      <td>-29.6068</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>ham</td>\n",
       "      <td>is serious spell name</td>\n",
       "      <td>-15.6137</td>\n",
       "      <td>-13.888</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>ham</td>\n",
       "      <td>i‘m go tri 2 month ha ha joke</td>\n",
       "      <td>-29.2269</td>\n",
       "      <td>-25.2452</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index label                                         clean_text spam_value  \\\n",
       "0      2  spam  free entri 2 wkli comp win fa cup final tkt 21...   -74.8796   \n",
       "1      3   ham                u dun say earli hor u c alreadi say   -33.1424   \n",
       "2      6   ham  even brother like speak me they treat like aid...   -38.4619   \n",
       "3      7   ham  as per request mell mell oru minnaminungint nu...   -67.9025   \n",
       "4     11  spam  six chanc win cash from 100 20000 pound txt cs...   -70.8023   \n",
       "5     13   ham  ive search right word thank breather i promis ...   -66.4925   \n",
       "6     17   ham  eh u rememb 2 spell name ye did he v naughti m...   -51.1316   \n",
       "7     18   ham             fine that way u feel that way gota b   -36.0186   \n",
       "8     20   ham                              is serious spell name   -15.6137   \n",
       "9     21   ham                      i‘m go tri 2 month ha ha joke   -29.2269   \n",
       "\n",
       "  ham_value Predicted_class  \n",
       "0  -93.0891            spam  \n",
       "1  -25.6572             ham  \n",
       "2  -32.6589             ham  \n",
       "3  -63.7573             ham  \n",
       "4  -87.7866            spam  \n",
       "5  -59.0313             ham  \n",
       "6  -44.1937             ham  \n",
       "7  -29.6068             ham  \n",
       "8   -13.888             ham  \n",
       "9  -25.2452             ham  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Evaluation </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold cross validation was used to evaluate the model. The dataset was split into five equal partitions where one fold was used as test set and the remaining folds were used as training set. The model evaluation metrics such as accuracy, precision, recall as well as confusion matrix were then used to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1115 1116 1117 ... 5569 5570 5571] TEST: [   0    1    2 ... 1112 1113 1114]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.9733499645615055\n",
      "Precision of model is: 0.9737846812948175\n",
      "Recall of model is: 0.9730941704035875\n",
      "Confusion matrix:\n",
      "[[928  19]\n",
      " [ 11 157]]\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [1115 1116 1117 ... 2227 2228 2229]\n",
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.9781930751254619\n",
      "Precision of model is: 0.9784638428356818\n",
      "Recall of model is: 0.9780269058295965\n",
      "Confusion matrix:\n",
      "[[1891   30]\n",
      " [  19  290]]\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [2230 2231 2232 ... 3341 3342 3343]\n",
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.9789197727882285\n",
      "Precision of model is: 0.9791589578671124\n",
      "Recall of model is: 0.9787683860527651\n",
      "Confusion matrix:\n",
      "[[2855   43]\n",
      " [  28  418]]\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [3344 3345 3346 ... 4455 4456 4457]\n",
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.9781386808887612\n",
      "Precision of model is: 0.9783269356035412\n",
      "Recall of model is: 0.9780170435790712\n",
      "Confusion matrix:\n",
      "[[3799   57]\n",
      " [  41  561]]\n",
      "TRAIN: [   0    1    2 ... 4455 4456 4457] TEST: [4458 4459 4460 ... 5569 5570 5571]\n",
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.978079694048056\n",
      "Precision of model is: 0.9783381205642524\n",
      "Recall of model is: 0.9779253045221438\n",
      "Confusion matrix:\n",
      "[[4751   74]\n",
      " [  49  698]]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits = 5, random_state = 0)\n",
    "scores = []\n",
    "precs = []\n",
    "recalls = []\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for train_index, test_index in cv.split(df):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "    vocab_df = get_vocab(df)\n",
    "    \n",
    "    train_df = df.iloc[train_index]\n",
    "    test_df = df.iloc[test_index]\n",
    " \n",
    "    vocab_df,total_prob_spam,total_prob_ham= for_each_class(vocab_df,train_df)\n",
    "    \n",
    "    test = predict(test_df, vocab_df, total_prob_spam,total_prob_ham) \n",
    "\n",
    "    #print(test.head(10))\n",
    "\n",
    "    confusion += confusion_matrix(test.label, test.Predicted_class)\n",
    "    score = f1_score(test.label, test.Predicted_class,pos_label=['ham','spam'],average= 'weighted')\n",
    "    scores.append(score)\n",
    "    \n",
    "    prec = precision_score(test.label, test.Predicted_class,pos_label=['ham','spam'],average= 'weighted')\n",
    "    precs.append(prec)\n",
    "    recall = recall_score(test.label, test.Predicted_class,pos_label=['ham','spam'],average= 'weighted')\n",
    "    recalls.append(recall)\n",
    "    \n",
    "\n",
    "    print('Total emails classified:', len(df))\n",
    "    print('Accuracy of model is:', np.mean(scores))\n",
    "    print('Precision of model is:', np.mean(precs))\n",
    "    print('Recall of model is:', np.mean(recalls))\n",
    "    print('Confusion matrix:')\n",
    "         \n",
    "    print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6. Conclusion</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the following values were obtained from the spam classifier model:\n",
    "    TP = 4751 (cases for which ham text message were actually predicted as ham)\n",
    "    FP = 74 (cases for which ham text message were incorrectly predicted spam)\n",
    "    FN = 49 (cases for which spam text message were incorrectly predicted as ham)\n",
    "    TN = 698 (cases for which spam text message were actually predicted as spam)\n",
    "    Accuracy = 97.80%\n",
    "    Precision = 97.83%\n",
    "    Recall = 97.79%\n",
    "\n",
    "Using this model, for each 100 text messages it classified, 97 were correctly classified. Around 3% of the \"ham\" text messages were incorrectly classified as \"Spam\". Similarly, the number of \"spam\" text messages that were incorrectly classified as \"Ham\" were only around 3%. These values were quite low which indicated that the model was quite precise.\n",
    "\n",
    "Although this model has good performance for given dataset, it might not work well with new dataset as it ignored words not found in vocabulary. This is one of the limitations that could be further studied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Comparison with existing Naive Bayes library </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1321: UserWarning: Note that pos_label (set to ['ham', 'spam']) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1115 1116 1117 ... 5569 5570 5571] TEST: [   0    1    2 ... 1112 1113 1114]\n",
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.9854678188643197\n",
      "Precision of model is: 0.9856017648005403\n",
      "Recall of model is: 0.9856502242152466\n",
      "Confusion matrix:\n",
      "[[944   3]\n",
      " [ 13 155]]\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [1115 1116 1117 ... 2227 2228 2229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1321: UserWarning: Note that pos_label (set to ['ham', 'spam']) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.9845343950454976\n",
      "Precision of model is: 0.9846560092663301\n",
      "Recall of model is: 0.9847533632286996\n",
      "Confusion matrix:\n",
      "[[1914    7]\n",
      " [  27  282]]\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [2230 2231 2232 ... 3341 3342 3343]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1321: UserWarning: Note that pos_label (set to ['ham', 'spam']) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.9854173392645901\n",
      "Precision of model is: 0.9856000370231385\n",
      "Recall of model is: 0.9856464671674274\n",
      "Confusion matrix:\n",
      "[[2890    8]\n",
      " [  40  406]]\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [3344 3345 3346 ... 4455 4456 4457]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1321: UserWarning: Note that pos_label (set to ['ham', 'spam']) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.9851664010003932\n",
      "Precision of model is: 0.9854164274164297\n",
      "Recall of model is: 0.9854197695856244\n",
      "Confusion matrix:\n",
      "[[3847    9]\n",
      " [  56  546]]\n",
      "TRAIN: [   0    1    2 ... 4455 4456 4457] TEST: [4458 4459 4460 ... 5569 5570 5571]\n",
      "Total emails classified: 5572\n",
      "Accuracy of model is: 0.9850582106718846\n",
      "Precision of model is: 0.9852527438107378\n",
      "Recall of model is: 0.9852837510365425\n",
      "Confusion matrix:\n",
      "[[4810   15]\n",
      " [  67  680]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1321: UserWarning: Note that pos_label (set to ['ham', 'spam']) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = KFold(n_splits = 5, random_state = 0)\n",
    "scores = []\n",
    "precs = []\n",
    "recalls = []\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for train_index, test_index in cv.split(df):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "    train_df = df.iloc[train_index]\n",
    "    test_df = df.iloc[test_index]\n",
    " \n",
    "    vectorizer = CountVectorizer()\n",
    "    counts = vectorizer.fit_transform(train_df['clean_text'].values)\n",
    "    test1 = vectorizer.transform(test_df['clean_text'].values)\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "    #Train the model using the training sets\n",
    "    classifier.fit(counts,train_df['label'].values)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    ypred = classifier.predict(test1)\n",
    "\n",
    "    #print(test.head(10))\n",
    "\n",
    "    confusion += confusion_matrix(test_df.label, ypred)\n",
    "    score = f1_score(test_df.label, ypred,pos_label=['ham','spam'],average= 'weighted')\n",
    "    scores.append(score)\n",
    "    \n",
    "    prec = precision_score(test_df.label, ypred,pos_label=['ham','spam'],average= 'weighted')\n",
    "    precs.append(prec)\n",
    "    recall = recall_score(test_df.label, ypred,pos_label=['ham','spam'],average= 'weighted')\n",
    "    recalls.append(recall)\n",
    "    \n",
    "\n",
    "    print('Total emails classified:', len(df))\n",
    "    print('Accuracy of model is:', np.mean(scores))\n",
    "    print('Precision of model is:', np.mean(precs))\n",
    "    print('Recall of model is:', np.mean(recalls))\n",
    "    print('Confusion matrix:')\n",
    "         \n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the existing Naive Bayes library, similar results were obtained with an accuracy of 98%, precision of 98% and recall of 98%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
